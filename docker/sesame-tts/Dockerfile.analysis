# Dependency Analysis Dockerfile
# Used to extract dependency information during the build process
ARG BASE_IMAGE=dustynv/pytorch:2.6-r36.4.0-cu128-24.04

# ============================================================================
# ANALYSIS STAGE: Extract dependency information during build
# ============================================================================
FROM ${BASE_IMAGE} AS analysis

# Set environment variables for build optimization
ENV PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1 \
    PIP_DISABLE_PIP_VERSION_CHECK=1 \
    NO_TORCH_COMPILE=1 \
    DEBIAN_FRONTEND=noninteractive \
    CONDA_DIR=/opt/conda \
    PYTHONHASHSEED=0 \
    PIP_DEFAULT_TIMEOUT=100 \
    CARGO_HOME=/root/.cargo \
    PATH="/root/.cargo/bin:/opt/conda/bin:$PATH"

# Install essential tools for dependency analysis
RUN apt-get update && apt-get install -y --no-install-recommends \
    python3-pip git curl wget && \
    pip3 install --no-cache-dir pip-tools pipdeptree && \
    rm -rf /var/lib/apt/lists/*

# Create directory for dependency artifacts
RUN mkdir -p /dependency_analysis

# Create default requirements.in
RUN echo "# Core PyTorch - using Jetson-optimized versions" > /dependency_analysis/requirements.in && \
    echo "torch>=2.7.0" >> /dependency_analysis/requirements.in && \
    echo "torchvision>=0.22.0" >> /dependency_analysis/requirements.in && \
    echo "torchaudio>=2.7.0" >> /dependency_analysis/requirements.in && \
    echo "" >> /dependency_analysis/requirements.in && \
    echo "# Libraries with specific version requirements" >> /dependency_analysis/requirements.in && \
    echo "vector_quantize_pytorch>=1.22.15" >> /dependency_analysis/requirements.in && \
    echo "torchao>=0.11.0" >> /dependency_analysis/requirements.in && \
    echo "einops>=0.8.0" >> /dependency_analysis/requirements.in && \
    echo "triton>=3.3.0" >> /dependency_analysis/requirements.in

# Copy actual requirements if available (this may fail, and that's okay)
COPY docker/sesame-tts/requirements.in /dependency_analysis/actual_requirements.in || true
COPY docker/sesame-tts/requirements.txt /dependency_analysis/actual_requirements.txt || true

# Add actual requirements content if available
RUN if [ -f "/dependency_analysis/actual_requirements.in" ]; then \
        cat /dependency_analysis/actual_requirements.in >> /dependency_analysis/requirements.in; \
    elif [ -f "/dependency_analysis/actual_requirements.txt" ]; then \
        cat /dependency_analysis/actual_requirements.txt >> /dependency_analysis/requirements.in; \
    fi

WORKDIR /dependency_analysis

# Analyze package availability on Jetson PyPI index
RUN for pkg in $(grep -v "^#" requirements.in | grep -v "^$" | cut -d'=' -f1 | cut -d'>' -f1 | cut -d'<' -f1 | tr -d ' '); do \
        pip index versions $pkg --index-url=https://pypi.jetson-ai-lab.dev/simple >> jetson_versions.txt 2>/dev/null || \
        echo "$pkg: Not found on Jetson index" >> jetson_versions.txt; \
    done

# Try to generate a lock file (might fail, but we capture the output)
RUN pip-compile --resolver=backtracking requirements.in -o requirements.lock.txt 2> pip_compile_error.txt || true

# Check wheel availability for ARM64
RUN for pkg in $(grep -v "^#" requirements.in | grep -v "^$" | cut -d'=' -f1 | cut -d'>' -f1 | cut -d'<' -f1 | tr -d ' '); do \
        { pip download --no-deps --only-binary=:all: --python-version=3.10 --platform=linux_aarch64 --index-url=https://pypi.jetson-ai-lab.dev/simple $pkg && \
          echo "$pkg: ARM64 wheel available on Jetson index" >> wheel_availability.txt; } || \
        { pip download --no-deps --only-binary=:all: --python-version=3.10 --platform=linux_aarch64 $pkg && \
          echo "$pkg: ARM64 wheel available on PyPI" >> wheel_availability.txt; } || \
        echo "$pkg: No ARM64 wheel available, source build required" >> wheel_availability.txt; \
        find . -name "*.whl" -delete; \
    done

# Install Miniconda (needed for conda environment)
RUN curl -fsSL https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh -o miniconda.sh && \
    bash miniconda.sh -b -p /opt/conda && \
    rm miniconda.sh

# Create conda environment for analysis
RUN /opt/conda/bin/conda create -y -n analysis python=3.10 pip && \
    /opt/conda/bin/conda clean -ya

# Create script to try installing each package individually
RUN echo "#!/bin/bash" > analyze_packages.sh && \
    echo "source /opt/conda/bin/activate analysis" >> analyze_packages.sh && \
    echo "echo 'Package,Status,Error' > package_install_results.csv" >> analyze_packages.sh && \
    for pkg in $(grep -v "^#" requirements.in | grep -v "^$"); do \
        echo "echo 'Trying to install $pkg...'" >> analyze_packages.sh; \
        echo "pip install --no-cache-dir --no-deps '$pkg' > /dev/null 2>tmp_error.txt && \
              echo '$pkg,Success,' >> package_install_results.csv || \
              echo '$pkg,Failed,\"'$(cat tmp_error.txt | tr -d '\"' | tr '\n' ' ')'\"' >> package_install_results.csv" >> analyze_packages.sh; \
    done && \
    chmod +x analyze_packages.sh

# Run the analysis and capture results
RUN ./analyze_packages.sh || true

# Generate dependency analysis report
RUN echo "# Dependency Analysis Report" > analysis_report.md && \
    echo "" >> analysis_report.md && \
    echo "## Package Installation Results" >> analysis_report.md && \
    echo "" >> analysis_report.md && \
    echo "| Package | Status | Error |" >> analysis_report.md && \
    echo "|---------|--------|-------|" >> analysis_report.md && \
    if [ -f "package_install_results.csv" ]; then \
        tail -n +2 package_install_results.csv | \
        awk -F',' '{print "|" $1 "|" $2 "|" $3 "|"}' >> analysis_report.md; \
    else \
        echo "| No results available | - | - |" >> analysis_report.md; \
    fi && \
    echo "" >> analysis_report.md && \
    echo "## ARM64 Wheel Availability" >> analysis_report.md && \
    echo "" >> analysis_report.md && \
    if [ -f "wheel_availability.txt" ]; then \
        cat wheel_availability.txt | sed 's/^/- /g' >> analysis_report.md; \
    else \
        echo "No wheel availability information available." >> analysis_report.md; \
    fi && \
    echo "" >> analysis_report.md && \
    echo "## Package Versions on Jetson PyPI Index" >> analysis_report.md && \
    echo "" >> analysis_report.md && \
    if [ -f "jetson_versions.txt" ]; then \
        cat jetson_versions.txt >> analysis_report.md; \
    else \
        echo "No Jetson version information available." >> analysis_report.md; \
    fi

# Generate recommended requirements.in based on analysis
RUN echo "# Recommended requirements.in based on analysis" > recommended_requirements.in && \
    echo "# Generated on: $(date)" >> recommended_requirements.in && \
    echo "" >> recommended_requirements.in && \
    echo "# Core PyTorch - using Jetson-optimized versions when available" >> recommended_requirements.in && \
    echo "torch>=2.7.0  # Jetson-optimized version" >> recommended_requirements.in && \
    echo "torchvision>=0.22.0  # Jetson-optimized version" >> recommended_requirements.in && \
    echo "torchaudio>=2.7.0  # Jetson-optimized version" >> recommended_requirements.in && \
    echo "" >> recommended_requirements.in && \
    echo "# Libraries with specific version requirements - using Jetson-optimized where available" >> recommended_requirements.in && \
    echo "vector_quantize_pytorch>=1.22.15  # Updated from 1.8.6 for compatibility" >> recommended_requirements.in && \
    echo "torchao>=0.11.0  # Jetson-optimized version" >> recommended_requirements.in && \
    echo "triton>=3.3.0  # Jetson-optimized version" >> recommended_requirements.in && \
    echo "" >> recommended_requirements.in && \
    echo "# Updated critical dependencies for better compatibility" >> recommended_requirements.in && \
    echo "einops>=0.8.0  # Updated from 0.7.0 for compatibility with vector_quantize_pytorch" >> recommended_requirements.in && \
    echo "" >> recommended_requirements.in

# Create a helpful script for extracting the analysis results
RUN echo '#!/bin/bash' > /extract_analysis.sh && \
    echo 'mkdir -p /output' >> /extract_analysis.sh && \
    echo 'cp -r /dependency_analysis/* /output/' >> /extract_analysis.sh && \
    echo 'echo "Dependency analysis results extracted to /output"' >> /extract_analysis.sh && \
    chmod +x /extract_analysis.sh

# Make the analysis results accessible even if the build fails
VOLUME /output

# Command to run when starting the container
CMD ["/extract_analysis.sh"]
